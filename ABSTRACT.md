In the realm of real-time traffic sign detection, the task of locating traffic signs within natural images poses a formidable challenge with significant industrial implications. The authors aim to address this gap through the **GTSDB: The German Traffic Sign Detection Benchmark** which was introduced as a competition at the International Joint Conference on Neural Networks (IJCNN) in 2013. They present a real-world benchmark dataset for traffic sign detection, complete with meticulously chosen evaluation metrics, baseline results, and a web interface for facilitating method comparisons. In their evaluation, the authors distinguish between sign detection and classification while assessing performance on relevant sign categories to facilitate the benchmarking of specialized solutions.

Many practical computer vision applications necessitate precise detection of contextually relevant objects within video images. Traffic sign recognition serves as a challenging example, as it demands algorithms capable of operating in complex, dynamic environments, while meeting stringent accuracy requirements and real-time constraints. Given its substantial industrial relevance, numerous approaches have been proposed for traffic sign detection and recognition. The automotive industry has even deployed advanced driver assistance systems featuring traffic sign recognition, albeit typically limited to a subset of possible signs. Despite these advancements, a comprehensive, impartial comparison of traffic sign detection systems is conspicuously absent, and suitably large benchmark datasets are not readily accessible.

Hence, the authors propose the GTSDB, encompassing an extensive dataset of real-world images and a systematic evaluation protocol, complemented by a public web interface. The traffic sign recognition process is divided into two primary stages: detection of signs within an image or video stream, followed by their subsequent recognition (classification). The benchmark dataset comprises images captured during tours near Bochum, Germany, in spring and autumn 2010. These images cover diverse scenarios, including urban, rural, and highway settings during both daytime and dusk, featuring varying weather conditions. The traffic signs recorded adhere to the Vienna Convention on Road Signs and Signals, ensuring a standardized appearance across 62 countries.

## Data Collection and Format
The authors used a Prosilica GC 1380CH camera with automatic exposure control to record Bayer-pattern images at a resolution of 1360×1024 pixels. For the final benchmark dataset, the images were cropped to 1360×800 pixels, as the lower portion primarily displayed the front lid and was not task-relevant. All images were converted to RGB color space using an edge-adaptive, constant-hue demosaicking method and were stored in raw PPM file format. All visible traffic signs in the images were manually labeled.

## Data Organization
The sizes of traffic signs varied between 16 and 128 pixels concerning the longer edge. The bounding boxes were not necessarily square due to the aspect ratio of the sign types and perspective distortions. The final dataset comprises 900 full images containing 1206 traffic signs, randomly divided into a training set (600 images, 846 traffic signs) and an evaluation set (300 images, 360 traffic signs). Images with identical real-world traffic signs were assigned to the same set, although most traffic sign instances occurred only once in the dataset. Consequently, the training set can be further subdivided for cross-validation purposes. Each image was annotated with rectangular regions of interest (ROIs) corresponding to the visible traffic signs and their specific traffic sign class (e.g., *stop sign*, *speed limit 60*, *speed limit 80*, etc.). Three competition-relevant categories were defined for the signs: ***prohibitory*** signs, ***mandatory*** signs, and ***danger*** signs. A small number of annotated signs did not fit into these categories and were deemed unimportant for the competition but were still included for the sake of completeness (***other***).

<img src="https://github.com/supervisely/dataset-tools/assets/78355358/06ef6d24-6bed-495d-9443-c3e51a48e560" alt="image" width="400">
